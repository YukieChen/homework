{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uh8nAS2dbVuF"
   },
   "source": [
    "# HW02 -- NeuralNetwork 葡萄酒分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8VbfwutbVuH"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMytAIN5bVuK"
   },
   "source": [
    "## 開啟資料檔 ##\n",
    "\n",
    "利用 Python With open as 語法開啟 wine.data，避免忘記關檔發生錯誤。開啟資料的同時也對資料進行以下幾項處理：\n",
    "1. 進行標準化\n",
    "1. 欄位轉置\n",
    "1. 打亂訓練資料\n",
    "\n",
    "### **進行標準化** ###\n",
    "\n",
    "原始資料並未進行標準化，最後的計算結果可能會受到某些數值較大的欄位嚴重影響，因此利用下列公式進行標準化：\n",
    "\n",
    "*(X - Min) / (Max - Min)*\n",
    "\n",
    "### **欄位轉置** ###\n",
    "原始的 wine.data 將分類放在第一欄，這不太符合一般習慣，因此將檔案重整，把分類放到最後一欄。\n",
    "\n",
    "逐一轉置的同時，設下一個標準值，並取一個亂數，若取得的亂數 > 標準值，則將該筆資料存至 test data；否則為 training data。\n",
    "\n",
    "### **打亂訓練資料** ###\n",
    "類神經網路進行學習時，若將資料分類的太好，則可能太早落入區域化最佳解而影響其正確率。所以將資料打亂，避免過早落入小區域最佳解。\n",
    "\n",
    "Python 提供 random.shuffle 函數可以打亂資料，這次使用 **D. E. Knuth** 的方法打亂訓練資料。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqRzZZldbVuP"
   },
   "outputs": [],
   "source": [
    "def openData(filename, split, trainingData = [], testData = []):\n",
    "    with open(filename, 'r') as csvData:\n",
    "        lines = csv.reader(csvData)\n",
    "        dataSet = list(lines)\n",
    "        dataItems = len(dataSet[0]) -1\n",
    "        \n",
    "        # 將資料進行標準化\n",
    "        for columns in range(1, len(dataSet[0])):\n",
    "            minX = float(dataSet[0][columns])\n",
    "            maxX = float(dataSet[0][columns])\n",
    "            \n",
    "            for x in range(len(dataSet)):\n",
    "                dataSet[x][columns] = float(dataSet[x][columns])\n",
    "                if dataSet[x][columns] <  minX:\n",
    "                    minX = dataSet[x][columns]\n",
    "                if dataSet[x][columns] >  maxX:\n",
    "                    maxX = dataSet[x][columns]\n",
    "            \n",
    "            for findMin in range(len(dataSet)):\n",
    "                dataSet[findMin][columns] = (dataSet[findMin][columns] - minX) / (maxX - minX)\n",
    "\n",
    "        # 讀入的 wine.data 分類結果在第一欄\n",
    "        # 將資料重整，將分類結果移到最後一欄\n",
    "        # data[x][0] - data[x][12] 為各項屬性的值\n",
    "        # data[x][13] 是分類結果\n",
    "        for x in range(len(dataSet)):\n",
    "            tempValue = dataSet[x][0]\n",
    "            for y in range(dataItems):\n",
    "                dataSet[x][y] = dataSet[x][y+1]\n",
    "            dataSet[x][-1] = tempValue\n",
    "            \n",
    "            # 利用亂數選取 training Data & testing Data\n",
    "            if random.random() < split:\n",
    "                trainingData.append(dataSet[x])\n",
    "            else:\n",
    "                testData.append(dataSet[x])\n",
    "\n",
    "        # 利用 D. E. Knuth 的方法打亂訓練資料\n",
    "        for i in range(len(trainingData)):\n",
    "            shuffleSeed = int(random.uniform(0, i))\n",
    "            tempValue = trainingData[i]\n",
    "            trainingData[i] = trainingData[shuffleSeed]\n",
    "            trainingData[shuffleSeed] = tempValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生起始參數 ##\n",
    "\n",
    "神經元需要有起始參數才能進行運算，因此需先產生起始參數。神經元進行計算時還需減去門檻值，所以參數的數量是資料維度 + 1。\n",
    "\n",
    "因為輸入的資料最後一欄是預先分類，祇要讀取 len(trainingData[0])，其值就已經是資料維度 + 1，也就是所需的參數數量。\n",
    "\n",
    "傳入資料：\n",
    "1. len(trainingData[0])\n",
    "1. 空陣列\n",
    "\n",
    "輸出資料：\n",
    "1. 擁有 len(trainingData[0]) 個元素的陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initWeight(dimension, weight = []):    \n",
    "    for i in range(dimension):\n",
    "        weight.append(random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練神經元 ##\n",
    "\n",
    "要傳入神經元的資料應該有：\n",
    "1. Learning rate\n",
    "1. 訓練資料集\n",
    "1. 起始參數\n",
    "\n",
    "神經元處理完之後要輸出的資料有：\n",
    "1. 修正後的參數\n",
    "\n",
    "傳入 Learning rate 的用意在於依據不同的訓練次數選擇不同的 Learning rate。原本將 Learning rate 放在最後一個參數，但 python 似乎不允許一般參數放在陣列之後，放到第一個參數才能執行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDxFFHyvoLlf"
   },
   "outputs": [],
   "source": [
    "def trainingNeuralNode(learningRate, trainingData = [], weight = []):\n",
    "    dimension = len(weight) - 1    # 資料集的每筆資料有幾個維度\n",
    "    dataNumber = len(trainingData)          # 資料集的資料總筆數\n",
    "    #選擇不同的 Learning rate\n",
    "    stepArray = [10, 1, 0.1, 0.01, 0.001]\n",
    "    step = stepArray[learningRate]\n",
    "    #如果祇想固定 learning rate, 將上兩行 comment 掉\n",
    "    #step = 0.1\n",
    "    \n",
    "    for i in range(dataNumber):\n",
    "        justify = 0\n",
    "        wineClass = int(trainingData[i][-1])\n",
    "        correct = 0 \n",
    "        \n",
    "        for j in range(dimension):\n",
    "            justify += trainingData[i][j] * weight[j]\n",
    "        justify += -1 * weight[dimension]\n",
    "        \n",
    "        if justify < 0:\n",
    "            correct = wineClass - 1\n",
    "        else:\n",
    "            correct = wineClass - 2\n",
    "        \n",
    "        for j in range(dimension):\n",
    "            weight[j] += step * trainingData[i][j] * correct\n",
    "            \n",
    "        weight[dimension] += step * (-1) * correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIWIGwQPbVub"
   },
   "source": [
    "## 計算正確率 ##\n",
    "\n",
    "將預測的結果與真正的結果做比較，並計算預測的正確率。\n",
    "\n",
    "輸入資料：\n",
    "1. 測試資料集\n",
    "1. 訓練階段獲得的參數值\n",
    "\n",
    "輸出資料：\n",
    "1. 正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bsea5A0fbVuc"
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testingData = [], weight = []):\n",
    "    dimension = len(weight) - 1            # 資料集的每筆資料有幾個維度\n",
    "    dataNumber = len(testingData)          # 資料集的資料總筆數\n",
    "    correct = 0 \n",
    "    \n",
    "    for i in range(dataNumber):\n",
    "        justify = 0\n",
    "        wineClass = int(testingData[i][-1])\n",
    "        \n",
    "        for j in range(dimension):\n",
    "            justify += testingData[i][j] * weight[j]\n",
    "        justify += -1 * weight[dimension]\n",
    "        \n",
    "        if justify < 0:\n",
    "            correct += (1 == wineClass)\n",
    "        else:\n",
    "            correct += (2 == wineClass)\n",
    "    \n",
    "    return (correct/float(len(testingData))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smByyVPubVuk"
   },
   "source": [
    "## 依 training 次數對正確率的影響畫圖 ##\n",
    "\n",
    "Training 次數太少可能會影響正確率，因此計算不同的 Training 次數的正確率改變。\n",
    "\n",
    "最後依照 training 次數與正確率的關係畫出折線圖，training 次數以 log 值呈現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Kqm9qtUbVuk"
   },
   "outputs": [],
   "source": [
    "def graphPlot(accuracy = []):\n",
    "    note = '' # 若標題需要增修，可修改此處的值\n",
    "    fileName = '' # 若檔名需要增加資訊，可修改此處的值\n",
    "    trainingAffect = []\n",
    "    minX = accuracy[0][1]\n",
    "    maxX = accuracy[0][1]\n",
    "    \n",
    "    for i in range(5):\n",
    "        if accuracy[i][1] < minX:\n",
    "            minX = accuracy[i][1]\n",
    "        if accuracy[i][1] > maxX:\n",
    "            maxX = accuracy[i][1]\n",
    "    minX = 5 * (int(minX / 5) - 3) # 為了畫圖好看，不會整個擠在一起\n",
    "    maxX = 5 * (int(maxX / 5) + 3) # 所以上下各加 10\n",
    "    \n",
    "    trainingAffectNP = np.asarray(accuracy, dtype= {'names': ['x', 'y'], 'formats':['f8','f8']})\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(trainingAffectNP['x'], trainingAffectNP['y'])\n",
    "    plt.xlabel('Training Times (10^X)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.tick_params(axis='x', rotation=45)\n",
    "    plt.title('Training Times V.S. Accuracy' + note )\n",
    "    plt.xticks(np.arange(0, 5, 1))\n",
    "    plt.yticks(np.arange(int(minX), int(maxX), 5))\n",
    "    plt.savefig('Training-Times-VS-Accuracy' + fileName + '.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較 training 次數對正確率的影響 ##\n",
    "\n",
    "挑選出訓練資料後，分別進行 1, 10, 100, 1000, 10000 次訓練，依序計算其正確率，比較不同訓練次數對於正確率的影響。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fpU2UhybVun"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    startTime = time.process_time()\n",
    "    \n",
    "    split = 0.5 # 設定訓練資料佔全體資料的比例\n",
    "    trainingData = []\n",
    "    testingData = []\n",
    "    weight = []\n",
    "    accuracy = []\n",
    "    \n",
    "    openData('wine2.data', split, trainingData, testingData)\n",
    "    initWeight(len(trainingData[0]), weight)\n",
    "    \n",
    "    for i in range(5):\n",
    "        # 測試在不同的訓練次數下，正確率的差異\n",
    "        # i = 0, 10**i = 1, 也就是完整讀完一次 tariningData\n",
    "        # i = 4, 10**i = 10000, 也就是訓練 10000 次。\n",
    "        for j in range(10**i):\n",
    "            trainingNeuralNode(i, trainingData, weight)\n",
    "\n",
    "        \n",
    "        # append 資料時要用 append( (x, y) ), 而不要用 append( [x, y] )\n",
    "        # 否則用 np 轉矩陣時會出錯，無法繪製圖形\n",
    "        accuracy.append((i, getAccuracy(testingData, weight)))\n",
    "            \n",
    "    graphPlot(accuracy)\n",
    "    \n",
    "    endTime = time.process_time()\n",
    "    # print('本次測試共進行 ' + repr(endTime - startTime) + ' 秒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "xgasUZv9bVup",
    "outputId": "48808da7-71f6-4d91-aff8-ab91b457366b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果 ##\n",
    "\n",
    "進行多次實驗後發現，以葡萄酒的資料進行機器學習，多數的情況祇需給予 10^2 (=100) 次的訓練就可讓錯誤率收斂於區域最小值，之後再給予更多的訓練也不會影響其正確性，甚至有幾次的實驗結果是訓練越多正確率反而降低。\n",
    "\n",
    "嘗試修改 Learning rate，在不同的訓練階段給予不同的 learning rate：第一次讀取資料時 learning rate = 10；前 10 次的訓練 learning rate = 1；前 100 次的訓練 learning rate = 0.1；第 100~1000 次的訓練 learning rate = 0.01；第 1000~10000 次的訓練 learning rate = 0.001，比較這樣的設定是否能更加逼進區域最佳解。但結果仍是 100 次訓練後就趨於穩定，不再有變化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論 ##\n",
    "\n",
    "**可能是葡萄酒資料特徵明顯，類別 overlap 不明顯**，因此祇需訓練 100 次就可以得到不錯的結果，甚至祇是完整的跑完一次 training data 就能讓正確率高於 50%。比起完全隨機的亂猜，僅僅是訓練一次就能擁有比隨機亂猜更好的結果。\n",
    "\n",
    "對 Neural Network 而言，重要的是各個輸入的 weight 值，為了得到更高的正確率，可以將 learning rate 調小一點，讓每次調整的步伐較小。\n",
    "\n",
    "降低 Learning rate 雖然需要較多次的訓練才能達到區域最佳解，但是因為調整的步伐小，更有可能趨近區域最佳解，而不會在最佳解的兩旁震盪。祇要給予足夠的時間進行訓練，就能得到較準確的 weight 值，還是值得的投資。\n",
    "\n",
    "但這次利用葡萄酒資料進行訓練時調整 learning rate 並沒有讓葡萄酒分類的正確率更高，其原因可能如前面所提到的：『葡萄酒資料特徵明顯，類別 overlap 不明顯』。在 overlap 不嚴重的情況下很容易將資料區分開，更趨近區域最佳解對於提高正確率並沒有幫助。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "神經網路-Wine.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
