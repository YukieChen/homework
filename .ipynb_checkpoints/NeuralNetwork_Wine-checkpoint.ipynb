{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uh8nAS2dbVuF"
   },
   "source": [
    "# Neural Network 葡萄酒分類器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8VbfwutbVuH"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMytAIN5bVuK"
   },
   "source": [
    "## 開啟資料檔 ##\n",
    "\n",
    "利用 Python With open as 語法開啟 wine.data，避免忘記關檔發生錯誤。開啟資料的同時也對資料進行以下幾項處理：\n",
    "1. 進行標準化\n",
    "1. 欄位轉置\n",
    "1. 打亂訓練資料\n",
    "\n",
    "### **進行標準化** ###\n",
    "\n",
    "原始資料並未進行標準化，最後的計算結果可能會受到某些數值較大的欄位嚴重影響，因此利用下列公式進行標準化：\n",
    "\n",
    "*(X - Min) / (Max - Min)*\n",
    "\n",
    "### **欄位轉置** ###\n",
    "原始的 wine.data 將分類放在第一欄，這不太符合一般習慣，因此將檔案重整，把分類放到最後一欄。\n",
    "\n",
    "逐一轉置的同時，設下一個標準值，並取一個亂數，若取得的亂數 > 標準值，則將該筆資料存至 test data；否則為 training data。\n",
    "\n",
    "### **打亂訓練資料** ###\n",
    "類神經網路進行學習時，若將資料分類的太好，則可能太早落入區域化最佳解而影響其正確率。所以將資料打亂，避免過早落入小區域最佳解。\n",
    "\n",
    "Python 提供 random.shuffle 函數可以打亂資料，這次使用 D. E. Knuth 的方法打亂訓練資料。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqRzZZldbVuP"
   },
   "outputs": [],
   "source": [
    "def openData(filename, split, trainingData = [], testData = []):\n",
    "    with open(filename, 'r') as csvData:\n",
    "        lines = csv.reader(csvData)\n",
    "        dataSet = list(lines)\n",
    "        dataItems = len(dataSet[0]) -1\n",
    "        \n",
    "        # 將資料進行標準化\n",
    "        for columns in range(1, len(dataSet[0])):\n",
    "            minX = float(dataSet[0][columns])\n",
    "            maxX = float(dataSet[0][columns])\n",
    "            \n",
    "            for x in range(len(dataSet)):\n",
    "                dataSet[x][columns] = float(dataSet[x][columns])\n",
    "                if dataSet[x][columns] <  minX:\n",
    "                    minX = dataSet[x][columns]\n",
    "                if dataSet[x][columns] >  maxX:\n",
    "                    maxX = dataSet[x][columns]\n",
    "            \n",
    "            for findMin in range(len(dataSet)):\n",
    "                dataSet[findMin][columns] = (dataSet[findMin][columns] - minX) / (maxX - minX)\n",
    "\n",
    "        # 讀入的 wine.data 分類結果在第一欄\n",
    "        # 將資料重整，將分類結果移到最後一欄\n",
    "        # data[x][0] - data[x][12] 為各項屬性的值\n",
    "        # data[x][13] 是分類結果\n",
    "        for x in range(len(dataSet)):\n",
    "            tempValue = dataSet[x][0]\n",
    "            for y in range(dataItems):\n",
    "                dataSet[x][y] = dataSet[x][y+1]\n",
    "            dataSet[x][-1] = tempValue\n",
    "            \n",
    "            # 利用亂數選取 training Data & testing Data\n",
    "            if random.random() < split:\n",
    "                trainingData.append(dataSet[x])\n",
    "            else:\n",
    "                testData.append(dataSet[x])\n",
    "\n",
    "        # 利用 D. E. Knuth 的方法打亂訓練資料\n",
    "        for i in range(len(trainingData)):\n",
    "            shuffleSeed = int(random.uniform(0, i))\n",
    "            tempValue = trainingData[i]\n",
    "            trainingData[i] = trainingData[shuffleSeed]\n",
    "            trainingData[shuffleSeed] = tempValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生起始參數 ##\n",
    "\n",
    "神經元需要有起始參數才能進行運算，因此需先產生起始參數。神經元進行計算時還需減去門檻值，所以參數的數量是資料維度 + 1。\n",
    "\n",
    "因為輸入的資料最後一欄是預先分類，祇要讀取 len(trainingData[0])，其值就已經是資料維度 + 1，也就是所需的參數數量。\n",
    "\n",
    "傳入資料：\n",
    "1. len(trainingData[0])\n",
    "1. 空陣列\n",
    "\n",
    "輸出資料：\n",
    "1. 擁有 len(trainingData[0]) 個元素的陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initWeight(dimension, weight = []):    \n",
    "    for i in range(dimension):\n",
    "        weight.append(random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練神經元 ##\n",
    "\n",
    "要傳入神經元的資料應該有：\n",
    "1. 訓練步距\n",
    "1. 訓練資料集\n",
    "1. 起始參數\n",
    "\n",
    "神經元處理完之後要輸出的資料有：\n",
    "1. 修正後的參數\n",
    "\n",
    "原本將訓練步距放在最後一個參數，但 python 似乎不允許一般參數放在陣列之後，放到第一個參數才能執行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDxFFHyvoLlf"
   },
   "outputs": [],
   "source": [
    "def trainingNeuralNode(choiseStep, trainingData = [], weight = []):\n",
    "    stepArray = [10, 1, 0.1, 0.01, 0.001]\n",
    "    dimension = len(weight) - 1    # 資料集的每筆資料有幾個維度\n",
    "    dataNumber = len(trainingData)          # 資料集的資料總筆數\n",
    "    step = stepArray[choiseStep]\n",
    "    \n",
    "    for i in range(dataNumber):\n",
    "        justify = 0\n",
    "        wineClass = int(trainingData[i][-1])\n",
    "        correct = 0 \n",
    "        \n",
    "        for j in range(dimension):\n",
    "            justify += trainingData[i][j] * weight[j]\n",
    "        justify += -1 * weight[dimension]\n",
    "        \n",
    "        if justify < 0:\n",
    "            correct = 1 - wineClass\n",
    "        else:\n",
    "            correct = 2 - wineClass\n",
    "        \n",
    "        for j in range(dimension):\n",
    "            weight[j] -= step * trainingData[i][j] * correct\n",
    "            \n",
    "        weight[dimension] -= step * (-1) * correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIWIGwQPbVub"
   },
   "source": [
    "## 計算正確率 ##\n",
    "\n",
    "將預測的結果與真正的結果做比較，並計算預測的正確率。\n",
    "\n",
    "輸入資料：\n",
    "1. 測試資料集\n",
    "1. 訓練階段獲得的參數值\n",
    "\n",
    "輸出資料：\n",
    "1. 正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bsea5A0fbVuc"
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testingData = [], weight = []):\n",
    "    dimension = len(weight) - 1            # 資料集的每筆資料有幾個維度\n",
    "    dataNumber = len(testingData)          # 資料集的資料總筆數\n",
    "    correct = 0 \n",
    "    \n",
    "    for i in range(dataNumber):\n",
    "        justify = 0\n",
    "        wineClass = int(testingData[i][-1])\n",
    "        \n",
    "        for j in range(dimension):\n",
    "            justify += testingData[i][j] * weight[j]\n",
    "        justify += -1 * weight[dimension]\n",
    "        \n",
    "        if justify < 0:\n",
    "            correct += (1 == wineClass)\n",
    "        else:\n",
    "            correct += (2 == wineClass)\n",
    "    \n",
    "    return (correct/float(len(testingData))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smByyVPubVuk"
   },
   "source": [
    "## 依據不同 training 次數對正確率的影響畫圖 ##\n",
    "\n",
    "Training 次數太少可能會影響正確率，因此計算不同的 Training 次數的正確率改變。\n",
    "\n",
    "最後依照 training 次數與正確率的關係畫出折線圖，training 次數以 log 值呈現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Kqm9qtUbVuk"
   },
   "outputs": [],
   "source": [
    "def graphPlot(accuracy = []):\n",
    "    note = '' # 若標題需要增修，可修改此處的值\n",
    "    fileName = '' # 若檔名需要增加資訊，可修改此處的值\n",
    "    trainingAffect = []\n",
    "    minX = accuracy[0][1]\n",
    "    maxX = accuracy[0][1]\n",
    "    \n",
    "    for i in range(5):\n",
    "        if accuracy[i][1] < minX:\n",
    "            minX = accuracy[i][1]\n",
    "        if accuracy[i][1] > maxX:\n",
    "            maxX = accuracy[i][1]\n",
    "    minX = 5 * (int(minX / 5) - 3) # 為了畫圖好看，不會整個擠在一起\n",
    "    maxX = 5 * (int(maxX / 5) + 3) # 所以上下各加 10\n",
    "    \n",
    "    trainingAffectNP = np.asarray(accuracy, dtype= {'names': ['x', 'y'], 'formats':['f8','f8']})\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(trainingAffectNP['x'], trainingAffectNP['y'])\n",
    "    plt.xlabel('Training Times (10^X)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.tick_params(axis='x', rotation=45)\n",
    "    plt.title('Training Times V.S. Accuracy' + note )\n",
    "    plt.xticks(np.arange(0, 5, 1))\n",
    "    plt.yticks(np.arange(int(minX), int(maxX), 5))\n",
    "    plt.savefig('Training-Times-VS-Accuracy' + fileName + '.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較不同 training 次數對正確率的影響 ##\n",
    "\n",
    "挑選出訓練資料後，分別進行 1, 10, 100, 1000, 10000 次訓練，依序計算其正確率，比較不同訓練次數對於正確率的影響。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fpU2UhybVun"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    startTime = time.process_time()\n",
    "    \n",
    "    split = 0.5 # 設定訓練資料佔全體資料的比例\n",
    "    trainingData = []\n",
    "    testingData = []\n",
    "    weight = []\n",
    "    accuracy = []\n",
    "    \n",
    "    openData('wine2.data', split, trainingData, testingData)\n",
    "    initWeight(len(trainingData[0]), weight)\n",
    "    \n",
    "    for i in range(5):\n",
    "        # 測試在不同的訓練次數下，正確率的差異\n",
    "        # i = 0, 10**i = 1, 也就是完整讀完一次 tariningData\n",
    "        # i = 4, 10**i = 10000, 也就是訓練 10000 次。\n",
    "        for j in range(10**i):\n",
    "            trainingNeuralNode(i, trainingData, weight)\n",
    "        \n",
    "        # append 資料時要用 append( (x, y) ), 而不要用 append( [x, y] )\n",
    "        # 否則用 np 轉矩陣時會出錯，無法繪製圖形\n",
    "        accuracy.append((i, getAccuracy(testingData, weight)))\n",
    "            \n",
    "    graphPlot(accuracy)\n",
    "    \n",
    "    endTime = time.process_time()\n",
    "    # print('本次測試共進行 ' + repr(endTime - startTime) + ' 秒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "xgasUZv9bVup",
    "outputId": "48808da7-71f6-4d91-aff8-ab91b457366b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果 ##\n",
    "\n",
    "進行多次實驗後發現，以葡萄酒的資料進行機器學習，多數的情況祇需給予 10^2 (=100) 次的訓練就可讓錯誤率收斂於區域最小值，之後再給予更多的訓練也不會影響其正確性，甚至有幾次的實驗結果是訓練越多正確率反而降低。\n",
    "\n",
    "少數幾次越訓練效果越差，可能是因為 learning ration 設為 0.1，使得調整的步伐過大，而無法落到區域最佳解，將 learning ration 調整為 0.01 之後這種越訓練效果越差的情況發生次數就隨之減少。\n",
    "\n",
    "但將 learning ration 從 0.1 調整為 0.01 仍然祇需訓練 100 次就可以得到 95% 以上的正確率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論 ##\n",
    "\n",
    "可能是葡萄酒資料特徵明顯，類別 overlap 不明顯，因此祇需訓練 100 次就可以得到不錯的結果，甚至祇是完整的跑完一次 training data 就能讓正確率高於 50%。比起完全隨機的亂猜，僅僅是訓練一次就能擁有比隨機亂猜更好的結果。\n",
    "\n",
    "為了得到更高的正確率，可以將 learning ration 調整為 0.01，每次調整的步伐雖然較小，需要較多次的訓練才能達到區域最佳解，但是因為調整的步伐小，更有可能趨近區域最佳解，而不會在最佳解的兩旁震盪。\n",
    "\n",
    "對 Neural Network 而言，重要的是各個輸入的 weight 值，learning ration 變小雖然調整的速度變慢，但祇要事先給予的時間進行訓練，就能得到較準確的 weight 值，還是值得的投資。\n",
    "\n",
    "日後會試著在不同的訓練階段給予不同的 learning ration，例如在前 100 次的訓練設定  learning ration = 0.1；第 100~1000 次的訓練設定  learning ration = 0.01；第 1000~10000 次的訓練設定  learning ration = 0.001，比較這樣的設定是否能更加逼進區域最佳解。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "神經網路-Wine.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
